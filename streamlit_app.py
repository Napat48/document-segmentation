import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import img2pdf
import tempfile
import os

def rotate_points_clockwise(pts, W, H):
    # (x, y) ‚Üí (y, W - x)
    new_pts = []
    for p in pts:
        x, y = p
        new_pts.append([y, W - x])
    return np.array(new_pts, dtype=np.float32)

def rotate_points_counter(pts, W, H):
    # (x, y) ‚Üí (H - y, x)
    new_pts = []
    for p in pts:
        x, y = p
        new_pts.append([H - y, x])
    return np.array(new_pts, dtype=np.float32)

def remove_shadow_preserve_color(img):
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)

    bg = cv2.medianBlur(v, 61)
    diff = cv2.absdiff(v, bg)
    shadow = cv2.normalize(255 - diff, None, 0, 255, cv2.NORM_MINMAX)

    v2 = cv2.addWeighted(v, 0.85, shadow, 0.15, 0)

    final_hsv = cv2.merge([h, s, v2])
    final = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)
    return final

def remove_shadow_white_color(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    result = cv2.adaptiveThreshold(
        gray, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        51, 10
    )
    return cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)

def safe_sharpen(img):
    kernel = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])
    return cv2.filter2D(img, -1, kernel)

def auto_shadow_removal(img):
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)

    S_std = np.std(s)      
    V_mean = np.mean(v)     
    V_std  = np.std(v)      
    V_med  = np.median(v)
    
    gray_pixels = np.sum(s < 30)   
    total_pixels = s.size
    gray_ratio = gray_pixels / total_pixels

    if gray_ratio > 0.70 :
        return remove_shadow_white_color(img)
    elif V_med > 140 and V_std < 40 and S_std < 25:
        return remove_shadow_white_color(img)
    else:
        return remove_shadow_preserve_color(img)

def enhance_final_preserve_color(img):
    img = auto_shadow_removal(img)
    img = safe_sharpen(img)
    return img

# start streamlit
st.title("üìÑ Multiple Document Scanner")
st.write("‡∏™‡πÅ‡∏Å‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ú‡πà‡∏ô‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‚Äî ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÉ‡∏ô‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏î‡∏µ‡∏¢‡∏ß")

uploaded = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£", type=["jpg","jpeg","png"])

if uploaded:

    model = YOLO("modelv2.pt")

    file_bytes = np.frombuffer(uploaded.read(), np.uint8)
    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    H, W = image.shape[:2]

    # Predict segmentation
    res = model.predict(image, conf=0.5)[0]

    if res.masks is None:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô‡∏†‡∏≤‡∏û")
        st.stop()

    masks = res.masks.data.cpu().numpy()
    upsampled_masks = []

    for m in masks:
        m = cv2.resize(m, (W, H), interpolation=cv2.INTER_LINEAR)
        m = (m * 255).astype(np.uint8)
        m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, np.ones((15,15), np.uint8))
        m = cv2.morphologyEx(m, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))
        upsampled_masks.append(m)

    contours = []
    for m in upsampled_masks:
        cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        contours.extend(cnts)

    min_area = 50000
    contours = [c for c in contours if cv2.contourArea(c) > min_area]

    if len(contours) == 0:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô‡∏†‡∏≤‡∏û")
        st.stop()

    contours = sorted(contours, key=cv2.contourArea, reverse=True)

    def order_points(pts):
        s = pts.sum(axis=1)
        diff = np.diff(pts, axis=1)
        return np.array([
            pts[np.argmin(s)],
            pts[np.argmin(diff)],
            pts[np.argmax(s)],
            pts[np.argmax(diff)]
        ], dtype="float32")

    A4_w, A4_h = 2480, 3508
    trim_border = 50

    output_images = []
    show_preview = st.checkbox("‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Preview)", value=True)

    for i, c in enumerate(contours):
    
        peri = cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, 0.02 * peri, True)
    
        if len(approx) != 4:
            rect = cv2.minAreaRect(c)
            approx = cv2.boxPoints(rect)
    
        approx_pts = approx.reshape(-1,2).astype(np.float32)
    
        # -------------------------------------
        # üî• Detect document orientation
        # -------------------------------------
        x, y, w_box, h_box = cv2.boundingRect(approx_pts)
        need_rotate = w_box > h_box   # ‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô
    
        # -------------------------------------
        # üî• Rotate ONLY the 4 corner points
        # -------------------------------------
        if need_rotate:
            H_img, W_img = image.shape[:2]
    
            # rotate 90¬∞ clockwise in pixel coordinates
            # (x, y) -> (y, W - x)
            rotated_pts = []
            for (x, y) in approx_pts:
                new_x = y
                new_y = W_img - x
                rotated_pts.append([new_x, new_y])
    
            approx_pts = np.array(rotated_pts, dtype=np.float32)
    
        # -------------------------------------
        # üî• Compute Homography normally
        # -------------------------------------
        src = order_points(approx_pts)
    
        dst = np.array([
            [0,0],
            [A4_w-1,0],
            [A4_w-1,A4_h-1],
            [0,A4_h-1]
        ], np.float32)
    
        H_mat, _ = cv2.findHomography(src, dst, cv2.RANSAC, 5.0)
    
        warped = cv2.warpPerspective(image, H_mat, (A4_w, A4_h))
    
        cropped = warped[
            trim_border:A4_h-trim_border,
            trim_border:A4_w-trim_border
        ]
    
        cropped = enhance_final_preserve_color(cropped)
    
        # üî• ‡∏´‡∏°‡∏∏‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡∏ñ‡πâ‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô
        if need_rotate:
            cropped = cv2.rotate(cropped, cv2.ROTATE_90_COUNTERCLOCKWISE)
    
        if show_preview:
            st.subheader(f"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏ô‡πâ‡∏≤ {i+1}")
            st.image(
                cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB),
                caption=f"Document {i+1}",
                use_column_width=True
            )
    
        output_images.append(cropped)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_pdf:

        image_paths = []

        for idx, img in enumerate(output_images):
            temp_path = f"/tmp/page_{idx}.jpg"
            cv2.imwrite(temp_path, img)
            image_paths.append(temp_path)

        tmp_pdf.write(img2pdf.convert(image_paths))

        for p in image_paths:
            os.remove(p)

        st.success("‚úî ‡∏™‡∏£‡πâ‡∏≤‡∏á PDF ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

        with open(tmp_pdf.name, "rb") as f:
            st.download_button(
                label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î PDF",
                data=f.read(),
                file_name="scanned_documents.pdf",
                mime="application/pdf"
            )
